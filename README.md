# üß† AI-Powered UPSC Chatbot using Gemini 2.0 Flash & Pinecone Vector DB

An intelligent Retrieval-Augmented Generation (RAG) chatbot that leverages **Google‚Äôs Gemini 2.0 Flash model** and **Pinecone Vector Database** to provide accurate, context-aware answers for UPSC exam preparation.

---

## üöÄ Features

- **RAG-based Contextual Answers:** Retrieves the most relevant information from your Pinecone vector store before generating responses.  
- **Powered by Gemini 2.0 Flash:** Uses Google‚Äôs cutting-edge generative AI model for intelligent and concise answers.  
- **Semantic Search with Sentence Transformers:** Converts queries into embeddings using `all-MiniLM-L6-v2`.  
- **Flask Web App:** Lightweight and interactive chat interface built using Flask and HTML templates.  
- **Scalable Vector Store:** Uses Pinecone for efficient similarity search and retrieval.  
- **Environment Secure:** Uses `.env` file for API keys and configuration secrets.  

---

## üß© Tech Stack

| Component | Technology |
|------------|-------------|
| **LLM** | Google Gemini 2.0 Flash |
| **Vector Database** | Pinecone |
| **Embedding Model** | Sentence Transformers (`all-MiniLM-L6-v2`) |
| **Framework** | Flask |
| **Frontend** | HTML + CSS (via `templates/chat.html`) |
| **Environment Management** | dotenv |
| **Language** | Python 3.11+ |


## üìÇ Project Structure

```

upsc-chatbot/
‚îÇ
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ chat.html                # Frontend chat interface
‚îÇ
‚îú‚îÄ‚îÄ app.py                       # Main Flask application
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ .env                         # Environment variables (excluded from Git)
‚îú‚îÄ‚îÄ .gitignore                   # Ignored files and folders
‚îî‚îÄ‚îÄ README.md                    # You are here!

````

---

## ‚öôÔ∏è Setup & Installation

Follow these steps to set up and run the chatbot locally:

### 1Ô∏è‚É£ Clone the Repository

```bash
git clone https://github.com/your-username/upsc-chatbot.git
cd upsc-chatbot
````

### 2Ô∏è‚É£ Create a Virtual Environment

```bash
python3 -m venv .venv
source .venv/bin/activate    # On Windows use: .venv\Scripts\activate
```

### 3Ô∏è‚É£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4Ô∏è‚É£ Configure Environment Variables

Create a `.env` file in the root directory and add your credentials:

```bash
GOOGLE_API_KEY="your-google-api-key"
PINECONE_API_KEY="your-pinecone-api-key"
```

> ‚ö†Ô∏è Keep your `.env` file private. Do not upload it to GitHub.

### 5Ô∏è‚É£ Run the Application

```bash
python app.py
```

The Flask app will start on:

```
http://127.0.0.1:8080
```

---

## üß† How It Works

1. **User Input:** The chatbot receives a query from the user interface.
2. **Embedding Generation:** The query is converted into vector embeddings using `sentence-transformers/all-MiniLM-L6-v2`.
3. **Vector Search:** The embeddings are sent to **Pinecone**, which retrieves the top 3 most relevant context chunks.
4. **Prompt Construction:** The retrieved text chunks are combined into a prompt for Gemini.
5. **Response Generation:** The **Gemini 2.0 Flash** model generates a context-based, accurate response.
6. **Display:** The answer is returned to the Flask front-end and displayed to the user.

---

## üß∞ Example Prompt Flow

**User Query:**

> What are the functions of the Election Commission of India?

**Model Workflow:**

1. Create embeddings ‚Üí Pinecone search for UPSC-related data.
2. Retrieve top 3 matching contexts.
3. Build RAG prompt ‚Üí Send to Gemini 2.0 Flash.
4. Return factual answer in human-readable format.

---

## üîê Environment Variables

| Variable              | Description                                           |
| --------------------- | ----------------------------------------------------- |
| `GOOGLE_API_KEY`      | API key for Google Gemini                             |
| `PINECONE_API_KEY`    | API key for Pinecone Vector DB                        |
| `PINECONE_INDEX_NAME` | Name of your Pinecone index (default: `upsc-chatbot`) |

---

## üìú License

This project is licensed under the MIT License. See the `LICENSE` file for more details.



## üß© Future Improvements

* [ ] Add chat history with context retention
* [ ] Integrate Streamlit or React frontend
* [ ] Add fine-tuned embedding models for domain-specific responses
* [ ] Deploy on Render / Hugging Face Spaces

---



## üë§ About The Author

Hi, I'm **Yash Desai** üëã

**Generative AI & LLM Engineer | Java ‚Ä¢ Python ‚Ä¢ Spring Boot | Exploring DevOps & SDET | Building Scalable AI Solutions**

With a strong foundation in Java backend engineering and a growing expertise in Generative AI, I specialize in building intelligent, production-ready applications that merge the robustness of enterprise systems with the innovation of Large Language Models (LLMs).

I thrive on designing solutions that are scalable, impactful, and deployment-ready‚Äîbridging backend reliability with AI innovation to deliver real-world value for businesses and communities.

<p align="left">
  <a href="https://www.linkedin.com/in/your-linkedin-profile" target="_blank">
    <img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn"/>
  </a>
  <a href="https://github.com/your-github-username" target="_blank">
    <img src="https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white" alt="GitHub"/>
  </a>
</p>


>‚≠ê If you like this project, don‚Äôt forget to star the repository!
