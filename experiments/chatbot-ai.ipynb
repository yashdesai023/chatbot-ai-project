{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67aa8fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time: 2025-10-07 15:55:06.211310\n",
      "Today's date: 2025-10-07\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.datetime.now()\n",
    "print(f\"Current date and time: {now}\")\n",
    "\n",
    "# Get just the current date\n",
    "today = datetime.date.today()\n",
    "print(f\"Today's date: {today}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9413b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain_pinecone langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35d400d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/chatbot/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/chatbot/lib/python3.11/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_pinecone import Pinecone as PineconeVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings # Replaces the deprecated import\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ecbdb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f32ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=\"pcsk_6JwCph_4qW3wjHMMVezzEChJ9FCUmc9Zuys4Tjf9zZESbY6RMWPQsaqHqYQzstjkhGai12\")\n",
    "index = pc.Index(\"upsc-chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfdc67a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pinecone.pinecone.Pinecone object at 0x72463c702cd0>\n"
     ]
    }
   ],
   "source": [
    "print(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275595fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb07d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dfb29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "753c9ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 5972\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbed3175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff55e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26df58c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b97a089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1948c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embeddings,\n",
    "    index_name=\"upsc-chatbot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20247f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# Initialize your connection to Pinecone\n",
    "pinecone.init(api_key=\"pcsk_6JwCph_4qW3wjHMMVezzEChJ9FCUmc9Zuys4Tjf9zZESbY6RMWPQsaqHqYQzstjkhGai12\", environment=\"YOUR_ENVIRONMENT\")\n",
    "\n",
    "# Specify the name of your existing index\n",
    "index_name = \"your-index-name\"\n",
    "\n",
    "# Connect to your index\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "print(\"Successfully connected to the existing index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f907267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected!\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# Paste the correct API key here\n",
    "api_key = \"pcsk_6JwCph_4qW3wjHMMVezzEChJ9FCUmc9Zuys4Tjf9zZESbY6RMWPQsaqHqYQzstjkhGai12\" \n",
    "\n",
    "# Initialize the client with the correct key\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "# Connect to your index\n",
    "index_name = \"upsc-chatbot\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "print(\"Successfully connected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "107a3669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the same model you used to create your index's data\n",
    "# Example: 'all-MiniLM-L6-v2' has a dimension of 384\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "\n",
    "# Your query text\n",
    "query_text = \"What is the first Chapter of the Indian Constitution?\"\n",
    "\n",
    "# Generate the embedding. This will be a list of 384 numbers.\n",
    "query_embedding = model.encode(query_text).tolist() \n",
    "\n",
    "# print(len(query_embedding)) # This should print 384\n",
    "# print(query_embedding[:5])  # Look at the first few numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5315d5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6482\n",
      "Text: I CHAPT __ \n",
      ") \n",
      "T\n",
      "he Indian Constitution is unique \n",
      "in its contents and spirit. Though \n",
      "borrowed from almost every Con-\n",
      "stitution of the world, the Constitution \n",
      "of India has several salient features that \n",
      "distinguish it from the Constitutions of the \n",
      "other countries. \n",
      "It should be noted at the outset that a num-\n",
      "ber of original features of the Constitution (as \n",
      "adopted in 1949)\"have undergone a substantial \n",
      "change, on account of several amendments,\n",
      "--------------------\n",
      "Score: 0.6482\n",
      "Text: I CHAPT __ \n",
      ") \n",
      "T\n",
      "he Indian Constitution is unique \n",
      "in its contents and spirit. Though \n",
      "borrowed from almost every Con-\n",
      "stitution of the world, the Constitution \n",
      "of India has several salient features that \n",
      "distinguish it from the Constitutions of the \n",
      "other countries. \n",
      "It should be noted at the outset that a num-\n",
      "ber of original features of the Constitution (as \n",
      "adopted in 1949)\"have undergone a substantial \n",
      "change, on account of several amendments,\n",
      "--------------------\n",
      "Score: 0.6467\n",
      "Text: ~-\n",
      "Basic Structure of the Constitution ~ 129 \n",
      "Table 12.1 Evolution of the Basic Structure of the Constitution \n",
      "51 Name of the Case (Year) Elements of the BaSIC Structure (As Declared by the \n",
      "No Supreme Court) \n",
      "1. Kesavananda Bharati Casel (1973) (popularly \n",
      "known as the Fundamental Rights Case) \n",
      "~ 2. Indira Nehru Gandhi Case3s (1975) (popularly \n",
      "known as the Election Case) \n",
      "3. \n",
      "I_ \n",
      "S. \n",
      "7. \n",
      "9. \n",
      "r 10. \n",
      "11. \n",
      "12. \n",
      "Minerva Mills Case4 (1980) \n",
      "Central Coal Fields Ltd. Cases (1980)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 2. Query your index with the REAL embedding\n",
    "query_response = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=3,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "# 3. Print the results\n",
    "for match in query_response['matches']:\n",
    "    print(f\"Score: {match['score']:.4f}\")\n",
    "    if 'text' in match['metadata']:\n",
    "        print(f\"Text: {match['metadata']['text']}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d61d39",
   "metadata": {},
   "source": [
    "### Test with RAG and Gemini Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ee69e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from pinecone import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# It's highly recommended to set these as environment variables\n",
    "# for security reasons.\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\", \"pcsk_6JwCph_4qW3wjHMMVezzEChJ9FCUmc9Zuys4Tjf9zZESbY6RMWPQsaqHqYQzstjkhGai12\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"AIzaSyCwYsOHp0AhssYMBULQANy-F--zIPwJqK0\")\n",
    "\n",
    "PINECONE_INDEX_NAME = \"upsc-chatbot\"\n",
    "# Important: Use the same model you used for creating embeddings in your DB\n",
    "EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "721072dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully connected to Pinecone index.\n",
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 9972}},\n",
      " 'total_vector_count': 9972,\n",
      " 'vector_type': 'dense'}\n",
      "✅ Embedding model loaded successfully.\n",
      "✅ Gemini model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pinecone\n",
    "try:\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    index = pc.Index(PINECONE_INDEX_NAME)\n",
    "    print(\"✅ Successfully connected to Pinecone index.\")\n",
    "    print(index.describe_index_stats())\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error connecting to Pinecone: {e}\")\n",
    "\n",
    "# Initialize the embedding model\n",
    "try:\n",
    "    embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "    print(\"✅ Embedding model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading embedding model: {e}\")\n",
    "\n",
    "# Initialize the Gemini model\n",
    "try:\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    llm = genai.GenerativeModel('gemini-2.0-flash')\n",
    "    print(\"✅ Gemini model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error configuring Gemini: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "910349fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_response(user_query):\n",
    "    \"\"\"\n",
    "    Takes a user query and returns a response from Gemini based on Pinecone context.\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve from Pinecone\n",
    "    query_embedding = embedding_model.encode(user_query).tolist()\n",
    "    query_results = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=3,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    context_chunks = [match['metadata']['text'] for match in query_results['matches']]\n",
    "    context_string = \"\\n\\n\".join(context_chunks)\n",
    "\n",
    "    # Step 2: Augment the Prompt for Gemini\n",
    "    prompt_template = f\"\"\"\n",
    "    You are a helpful assistant for the UPSC exam. \n",
    "    Answer the following question based ONLY on the context provided below.\n",
    "    If the context does not contain the answer, say \"I do not have enough information to answer that question.\"\n",
    "\n",
    "    CONTEXT:\n",
    "    {context_string}\n",
    "\n",
    "    QUESTION:\n",
    "    {user_query}\n",
    "\n",
    "    ANSWER:\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 3: Generate the Response with Gemini\n",
    "    try:\n",
    "        response = llm.generate_content(prompt_template)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while generating the response: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8432642f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- UPSC Chatbot ---\n",
      "Ask a question about the documents you've stored. Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759853420.716556   12754 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: The term 'Preamble' refers to the introduction or preface to the Constitution. It contains the summary or essence of the Constitution.\n",
      "\n",
      "\n",
      "AI: The Preamble is the introduction or preface to the Constitution. It contains the summary or essence of the Constitution. N.A. Palkhivala called the Preamble the 'identity card of the Constitution'. The Indian Constitution's Preamble is based on the 'Objectives Resolution'. The American Constitution was the first to begin with a Preamble, and many countries, including India, followed this practice.\n",
      "\n",
      "\n",
      "AI: I do not have enough information to answer that question.\n",
      "\n",
      "\n",
      "AI: I do not have enough information to answer that question.\n",
      "\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- UPSC Chatbot ---\")\n",
    "print(\"Ask a question about the documents you've stored. Type 'exit' to quit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nYou: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    # Get the response from our RAG function\n",
    "    ai_response = get_rag_response(user_input)\n",
    "    print(f\"\\nAI: {ai_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd3b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
